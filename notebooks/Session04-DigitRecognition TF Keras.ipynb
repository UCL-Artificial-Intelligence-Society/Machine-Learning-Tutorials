{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCL AI Society Machine Learning Tutorials\n",
    "### Session 04. Hand written digit recognition (TF and Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "1. Perceptrons\n",
    "2. Digit recognition using Tensorflow\n",
    "3. Digit recognition using Pytorch\n",
    "\n",
    "### Aim\n",
    "At the end of this session, you will be able to:\n",
    "- understand perceptrons in logistic regression mindset\n",
    "- understand feed-forward ANN\n",
    "- feel the differences of top two famous DL framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !! Your mission is to improve this recognizer !!\n",
    "\n",
    "**You can improve this by**:  \n",
    "- Different preprocessing method\n",
    "    - Normalisation\n",
    "    - Label Encoding\n",
    "- Hyperparameter Tuning \n",
    "    - Number of nodes\n",
    "    - learning rate\n",
    "    - dropout rate\n",
    "    - activations\n",
    "    - epochs\n",
    "    - batch size\n",
    "    - type of loss function\n",
    "- Better optimiser\n",
    "- Better architecture of perceptrons\n",
    "- Convolutional Neural Network\n",
    "- Regularisation\n",
    "    - Batch Normalisation\n",
    "    - Dropout\n",
    "- Learning rate scheduling\n",
    "- Early stopping\n",
    "\n",
    "**If these techniques are not familiar with you, don't worry! cuz we haven't covered those yet!  \n",
    "However, there are tons of good resources out there once you Google it!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the digit data from [https://www.kaggle.com/c/digit-recognizer](https://www.kaggle.com/c/digit-recognizer)  \n",
    "2. Unzip the folder and place it under the ./data directory\n",
    "3. file path should be: \"./data/digit-recognizer/CSV FILE NAME.csv\"\n",
    "\n",
    "**After you complete this notebook you can submit your prediction on Kaggle and check your Accuracy and ranking on the leaderboard**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/digit-recognizer/train.csv\")\n",
    "test = pd.read_csv(\"./data/digit-recognizer/test.csv\")\n",
    "X_train = train.drop(labels=[\"label\"], axis=1)\n",
    "Y_train = train['label']\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe you can normalise your dataset here?\n",
    "\n",
    "# reshape\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: improve this simple model.\n",
    "# at least set activation function for each layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(28,28,1)))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs,\n",
    "                    validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8,4))\n",
    "\n",
    "axes[0].plot(history.history['val_loss'], color='b', label=\"val loss\")\n",
    "axes[0].set_title(\"Vali Loss\")\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history.history['val_accuracy'], color='r', label=\"val acc\")\n",
    "axes[1].set_title(\"Vali Acc\")\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Acc\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "pred_classes = np.argmax(pred, axis = 1)\n",
    "result = pd.Series(pred_classes, name=\"Label\")\n",
    "\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"), result],axis = 1)\n",
    "\n",
    "submission.to_csv(\"./data/digit-recognizer/submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise your predictions\n",
    "\n",
    "fig,ax=plt.subplots(2,3,figsize=(15,10))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        selected_rand = np.random.randint(0,len(test))\n",
    "        img = test[selected_rand]\n",
    "        img = img.reshape((28,28))\n",
    "        ax[i][j].imshow(img)\n",
    "        ax[i][j].set_title(pred_classes[selected_rand],fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
