{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCL AI Society Machine Learning Tutorials\n",
    "### Session 03. Unsupervised learning - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "1. Data Pre-processing and Dimensionality Reduction\n",
    "2. Support Vector Machine (SVM)\n",
    "3. Clustering: Kmeans\n",
    "\n",
    "### Aim \n",
    "At the end of this session, you will be able to:  \n",
    "\n",
    "- Clean your dataset and reduce its redundancy.\n",
    "- Implement two of the most important ML model: SVM and Kmeans\n",
    "- Understand the differences between unsupervised and supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn PCA before doing this notebook\n",
    "# We use PCA without explanation.\n",
    "# However, you need to know that PCA is often used in unsupervised learning to simplify the dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About Clustering. Useful Websites. Please take your time to read.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developers.google.com/machine-learning/clustering/clustering-algorithms  \n",
    "https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68  \n",
    "https://towardsdatascience.com/k-means-clustering-of-wine-data-95bac074baae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans Clustering step-by-step visualisation\n",
    "![kmeans](https://miro.medium.com/max/960/1*KrcZK0xYgTa4qFrVr0fO2w.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clustering Wine Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.data.shape, wine.target.shape, wine.target_names, wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.data\n",
    "y = wine.target\n",
    "feature_names = wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_wine(X, labels=None, col_in_X=(0,1), set_labels=False):\n",
    "    \"\"\"\n",
    "    Since you can only graph two columns, this function takes two column indices in X which are to be drawn.\n",
    "    @param: X        --> Data\n",
    "    @param: lables   --> Default is set to None, but if you've got your result of labels from clustering, \n",
    "                         you can input according labels in a list format.\n",
    "    @param: col_in_X --> column index of dataset X to be selected for plotting.\n",
    "                         two-element tuple if you want 2D graph,\n",
    "                         three-element tuple if you want 3D graph.\n",
    "    @param: feature_names\n",
    "    \"\"\"\n",
    "    assert type(col_in_X) is tuple\n",
    "    \n",
    "    if len(col_in_X)==2:  # 2D\n",
    "        first_col, second_col = col_in_X[0], col_in_X[1]\n",
    "        \n",
    "        if set_labels:\n",
    "            plt.xlabel(feature_names[first_col])\n",
    "            plt.ylabel(feature_names[second_col])\n",
    "            \n",
    "        plt.scatter(X[:, first_col], X[:, second_col], c=labels)\n",
    "        \n",
    "    elif len(col_in_X)==3:  # 3D\n",
    "        first_col, second_col, third_col = col_in_X[0], col_in_X[1], col_in_X[2]\n",
    "        fig = plt.figure()\n",
    "        plt.clf()\n",
    "        ax = Axes3D(fig, elev=20)  # elev is an elevation of viewing angle (default: 30)\n",
    "\n",
    "        plt.cla()\n",
    "        \n",
    "        if set_labels:\n",
    "            ax.set_xlabel(feature_names[first_col])\n",
    "            ax.set_ylabel(feature_names[second_col])\n",
    "            ax.set_zlabel(feature_names[third_col])\n",
    "\n",
    "        ax.scatter(X[:, first_col], X[:, second_col], X[:, third_col], c=labels)\n",
    "        \n",
    "    else:\n",
    "        raise RuntimeError(\"Your dimension should be either set to \\\"2d\\\" or \\\"3d\\\"\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out different col_in_X and get some feeling of how the data is shaped.\n",
    "visualise_wine(X, labels=y, col_in_X=(8, 10, 12), set_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_wine(X, labels=y, col_in_X=(8, 10), set_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will run PCA on our wine dataset before clustering into groups.\n",
    "# TODO: complete run_PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_PCA(X, num_components=2):\n",
    "    # TODO: load PCA object with n_components\n",
    "    pca = None\n",
    "    # TODO: fit\n",
    "    pca.None\n",
    "    # TODO: transform the data\n",
    "    reduced_array = pca.None\n",
    "    \n",
    "    return reduced_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use euclidean distance for calculating the distance between two data points.\n",
    "# TODO: either use scipy distance library or manually implement euclidean distance.\n",
    "# Manual implementation is very easy.\n",
    "# Method: x1 - x2 is difference. square it, sum it, and then apply sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your own KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, initial_centroid_indices, num_clusters=3):\n",
    "\n",
    "    N = len(X)\n",
    "    centroids = X[initial_centroid_indices]\n",
    "    # TODO: initialise labels with N zeros. we are just making a placeholder for prediction of labels. Use numpy\n",
    "    labels = np.None\n",
    "\n",
    "    while True:\n",
    "        '''\n",
    "        Step 1. \n",
    "        Find the nearest centroid for each data point\n",
    "        and allocate your data point to according cluster.\n",
    "        When finding the nearest centroid, you use euclidean distance\n",
    "        '''\n",
    "        is_changed = False\n",
    "        for i in range(N):\n",
    "            distances = []\n",
    "            for k in range(num_clusters):\n",
    "                # TODO: Get the distance between i'th X and k'th centroid\n",
    "                k_dist = None\n",
    "                distances.append(k_dist)\n",
    "\n",
    "            if labels[i] != np.argmin(distances):\n",
    "                is_changed = True\n",
    "            labels[i] = np.argmin(distances)\n",
    "\n",
    "        '''\n",
    "        Step 2. \n",
    "        Calculate new centroid based on new cluster.\n",
    "        Centroid is a mean of data points in a cluster.\n",
    "        '''\n",
    "        for k in range(num_clusters):\n",
    "            x = X[labels == k][:, 0]\n",
    "            y = X[labels == k][:, 1]\n",
    "            \n",
    "            # TODO: update x and y with mean\n",
    "            x = None\n",
    "            y = None\n",
    "\n",
    "            centroids[k] = [x, y]\n",
    "\n",
    "        '''\n",
    "        Step 3. \n",
    "        Allocation did not change.\n",
    "        '''\n",
    "        if not is_changed:\n",
    "            break\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will normalize our input X before doing any calculation. \n",
    "# This is to feed a better quality data into our PCA and KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not a todo, but do note that this technique is used very often in ML\n",
    "# TODO: understand what this function is doing\n",
    "def normalize(X):\n",
    "    for dim in range(len(X[0])):\n",
    "        X[:, dim] -= np.min(X[:, dim])\n",
    "        X[:, dim] /= np.max(X[:, dim])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(X):\n",
    "    X = normalize(X)\n",
    "    pca_X = run_PCA(X, num_components=2)\n",
    "    # TODO: do kmeans with 2-dimensional data (PCA'ed)\n",
    "    # TODO: initialise centroid incides with a list of three random indices\n",
    "    # TODO: we want to cluster this into 3 clusters now, but try with different number of clusters\n",
    "    # Open question: is there any way you can effectively initialise intitial centorid position rather than just random?\n",
    "    pred_labels = kmeans(None)\n",
    "    visualise_wine(pca_X, labels=pred_labels)\n",
    "    \n",
    "    return pca_X, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred_labels = main(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels, len(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe we could use hamming distance as an evaluation metric for this particular task?\n",
    "# The Hamming distance between 1-D arrays u and v, is simply the proportion of disagreeing components in u and v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "distance.hamming(pred_labels, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open questions  (very important to think about)\n",
    "**1. How can you effectively evaluate your clustering algorithm?**  \n",
    "you can look up Dunn Index\n",
    "\n",
    "**2. In which situation can K-Means algorithm underperform?**  \n",
    "you can look up different clustering algorithms. That will explain advantages and disadvantages of K-Means.\n",
    "\n",
    "**3. Is there any way you can effectively initialise intitial centorid position rather than just random?**  \n",
    "\n",
    "**4. Is there any way you can effectively choose K ?**  \n",
    "Look up Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional \n",
    "**Code below is copied from https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html  \n",
    "All the credit for this code belongs to scikit-learn documentation, Gaël Varoquaux and Jaques Grobler**\n",
    "\n",
    "Congratulations! You have manually implemented KMeans clustering algorithm. Now let's see how you can use it in scikit-learn library.  \n",
    "You will be very familiar with the iris dataset, so we brought the code that uses it. You will be able to understand this code if you've followed this notebook so far.\n",
    "\n",
    "Reference this documentation to learn KMeans library in-depth:  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Though the following import is not directly being used, it is required\n",
    "# for 3D projection to work\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "estimators = [('k_means_iris_8', KMeans(n_clusters=8)),\n",
    "              ('k_means_iris_3', KMeans(n_clusters=3)),\n",
    "              ('k_means_iris_bad_init', KMeans(n_clusters=3, n_init=1,\n",
    "                                               init='random'))]\n",
    "\n",
    "fignum = 1\n",
    "titles = ['8 clusters', '3 clusters', '3 clusters, bad initialization']\n",
    "for name, est in estimators:\n",
    "    fig = plt.figure(fignum, figsize=(4, 3))\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "    est.fit(X)\n",
    "    labels = est.labels_\n",
    "\n",
    "    ax.scatter(X[:, 3], X[:, 0], X[:, 2],\n",
    "               c=labels.astype(np.float), edgecolor='k')\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('Petal width')\n",
    "    ax.set_ylabel('Sepal length')\n",
    "    ax.set_zlabel('Petal length')\n",
    "    ax.set_title(titles[fignum - 1])\n",
    "    ax.dist = 12\n",
    "    fignum = fignum + 1\n",
    "\n",
    "# Plot the ground truth\n",
    "fig = plt.figure(fignum, figsize=(4, 3))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "for name, label in [('Setosa', 0),\n",
    "                    ('Versicolour', 1),\n",
    "                    ('Virginica', 2)]:\n",
    "    ax.text3D(X[y == label, 3].mean(),\n",
    "              X[y == label, 0].mean(),\n",
    "              X[y == label, 2].mean() + 2, name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.2, edgecolor='w', facecolor='w'))\n",
    "# Reorder the labels to have colors matching the cluster results\n",
    "y = np.choose(y, [1, 2, 0]).astype(np.float)\n",
    "ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=y, edgecolor='k')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('Petal width')\n",
    "ax.set_ylabel('Sepal length')\n",
    "ax.set_zlabel('Petal length')\n",
    "ax.set_title('Ground Truth')\n",
    "ax.dist = 12\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
